Modelo de agente FastAPI LangGraph
Um modelo FastAPI pronto para produÃ§Ã£o para a criaÃ§Ã£o de aplicaÃ§Ãµes de agentes de IA com integraÃ§Ã£o LangGraph. Este modelo fornece uma base sÃ³lida para a construÃ§Ã£o de serviÃ§os de agentes de IA escalÃ¡veis, seguros e de fÃ¡cil manutenÃ§Ã£o.

ğŸŒŸ Recursos
Arquitetura pronta para produÃ§Ã£o

FastAPI para endpoints de API assÃ­ncronos de alto desempenho com otimizaÃ§Ã£o uvloop
IntegraÃ§Ã£o do LangGraph para fluxos de trabalho de agentes de IA com persistÃªncia de estado.
Langfuse para observabilidade e monitoramento de LLM
Registro estruturado com formataÃ§Ã£o especÃ­fica do ambiente e contexto de solicitaÃ§Ã£o.
LimitaÃ§Ã£o de taxa com regras configurÃ¡veis â€‹â€‹por endpoint
PostgreSQL com pgvector para persistÃªncia de dados e armazenamento vetorial.
Suporte para Docker e Docker Compose
MÃ©tricas do Prometheus e painÃ©is do Grafana para monitoramento
Recursos de IA e LLM

MemÃ³ria de longo prazo com mem0ai e pgvector para armazenamento de memÃ³ria semÃ¢ntica
ServiÃ§o LLM com lÃ³gica de repetiÃ§Ã£o automÃ¡tica usando tenacidade
Suporte a vÃ¡rios modelos LLM (GPT-4o, GPT-4o-mini, GPT-5, GPT-5-mini, GPT-5-nano)
TransmissÃ£o de respostas para interaÃ§Ãµes de chat em tempo real
Capacidades de chamada de ferramentas e execuÃ§Ã£o de funÃ§Ãµes
SeguranÃ§a

AutenticaÃ§Ã£o baseada em JWT
GestÃ£o de sessÃµes
sanitizaÃ§Ã£o de entrada
ConfiguraÃ§Ã£o CORS
ProteÃ§Ã£o de limitaÃ§Ã£o de taxa
ExperiÃªncia do desenvolvedor

ConfiguraÃ§Ã£o especÃ­fica do ambiente com carregamento automÃ¡tico de arquivos .env
Sistema de registro abrangente com vinculaÃ§Ã£o de contexto
Estrutura de projeto clara seguindo as melhores prÃ¡ticas
Dicas de digitaÃ§Ã£o ao longo do texto para melhor suporte do IDE
ConfiguraÃ§Ã£o de desenvolvimento local simplificada com comandos Makefile.
LÃ³gica de repetiÃ§Ã£o automÃ¡tica com recuo exponencial para resiliÃªncia
Estrutura de AvaliaÃ§Ã£o do Modelo

AvaliaÃ§Ã£o automatizada de resultados de modelos com base em mÃ©tricas
IntegraÃ§Ã£o com Langfuse para anÃ¡lise de traÃ§os
RelatÃ³rios JSON detalhados com mÃ©tricas de sucesso/falha
Interface de linha de comando interativa
MÃ©tricas de avaliaÃ§Ã£o personalizÃ¡veis
ğŸš€ InÃ­cio RÃ¡pido
PrÃ©-requisitos
Python 3.13+
PostgreSQL ( consulte ConfiguraÃ§Ã£o do banco de dados )
Docker e Docker Compose (opcional)
ConfiguraÃ§Ã£o do ambiente
Clone o repositÃ³rio:
git clone <repository-url>
cd <project-directory>
Criar e ativar um ambiente virtual:
uv sync
Copie o arquivo de ambiente de exemplo:
cp .env.example .env.[development|staging|production] # e.g. .env.development
Atualize o .envarquivo com sua configuraÃ§Ã£o (consulte .env.examplepara referÃªncia).
ConfiguraÃ§Ã£o do banco de dados
Crie um banco de dados PostgreSQL (por exemplo, Supabase ou PostgreSQL local).
Atualize as configuraÃ§Ãµes de conexÃ£o do banco de dados no seu .envarquivo:
POSTGRES_HOST=db
POSTGRES_PORT=5432
POSTGRES_DB=cool_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
VocÃª nÃ£o precisa criar as tabelas manualmente, o ORM cuidarÃ¡ disso para vocÃª. Mas, caso encontre algum problema, execute o schemas.sqlarquivo para criar as tabelas manualmente.
Executando o aplicativo
Desenvolvimento Local
Instalar dependÃªncias:
uv sync
Execute o aplicativo:
make [dev|staging|prod] # e.g. make dev
Acesse a interface do Swagger:
http://localhost:8000/docs
Usando o Docker
Crie e execute com Docker Compose:
make docker-build-env ENV=[development|staging|production] # e.g. make docker-build-env ENV=development
make docker-run-env ENV=[development|staging|production] # e.g. make docker-run-env ENV=development
Acesse a pilha de monitoramento:
# Prometheus metrics
http://localhost:9090

# Grafana dashboards
http://localhost:3000
Default credentials:
- Username: admin
- Password: admin
A configuraÃ§Ã£o do Docker inclui:

AplicaÃ§Ã£o FastAPI
banco de dados PostgreSQL
Prometheus para coleta de mÃ©tricas
Grafana para visualizaÃ§Ã£o de mÃ©tricas
PainÃ©is prÃ©-configurados para:
MÃ©tricas de desempenho da API
estatÃ­sticas de limitaÃ§Ã£o de taxa
Desempenho do banco de dados
UtilizaÃ§Ã£o de recursos do sistema
ğŸ“Š AvaliaÃ§Ã£o do Modelo
O projeto inclui uma estrutura de avaliaÃ§Ã£o robusta para medir e acompanhar o desempenho do modelo ao longo do tempo. O avaliador busca automaticamente os dados de rastreamento do Langfuse, aplica as mÃ©tricas de avaliaÃ§Ã£o e gera relatÃ³rios detalhados.

Executando avaliaÃ§Ãµes
VocÃª pode executar avaliaÃ§Ãµes com diferentes opÃ§Ãµes usando os comandos Makefile fornecidos:

# Interactive mode with step-by-step prompts
make eval [ENV=development|staging|production]

# Quick mode with default settings (no prompts)
make eval-quick [ENV=development|staging|production]

# Evaluation without report generation
make eval-no-report [ENV=development|staging|production]
CaracterÃ­sticas de avaliaÃ§Ã£o
CLI interativa : Interface amigÃ¡vel com saÃ­da colorida e barras de progresso.
ConfiguraÃ§Ã£o flexÃ­vel : defina valores padrÃ£o ou personalize em tempo de execuÃ§Ã£o.
RelatÃ³rios detalhados : RelatÃ³rios JSON com mÃ©tricas abrangentes, incluindo:
Taxa de sucesso geral
Desempenho especÃ­fico da mÃ©trica
InformaÃ§Ãµes sobre duraÃ§Ã£o e horÃ¡rios
Detalhes de sucesso/falha em nÃ­vel de rastreamento
Personalizando mÃ©tricas
As mÃ©tricas de avaliaÃ§Ã£o sÃ£o definidas em evals/metrics/prompts/arquivos Markdown:

Crie um novo arquivo Markdown (por exemplo, my_metric.md) no diretÃ³rio de prompts.
Defina os critÃ©rios de avaliaÃ§Ã£o e a lÃ³gica de pontuaÃ§Ã£o.
O avaliador irÃ¡ detectar e aplicar automaticamente sua nova mÃ©trica.
RelatÃ³rios de visualizaÃ§Ã£o
Os relatÃ³rios sÃ£o gerados automaticamente no evals/reports/diretÃ³rio com os registros de data e hora no nome do arquivo:

evals/reports/evaluation_report_YYYYMMDD_HHMMSS.json
Cada relatÃ³rio inclui:

EstatÃ­sticas de alto nÃ­vel (contagem total de rastros, taxa de sucesso, etc.)
MÃ©tricas de desempenho por mÃ©trica
InformaÃ§Ãµes detalhadas em nÃ­vel de rastreamento para depuraÃ§Ã£o
ğŸ”§ ConfiguraÃ§Ã£o
O aplicativo utiliza um sistema de configuraÃ§Ã£o flexÃ­vel com configuraÃ§Ãµes especÃ­ficas para cada ambiente:

.env.development- ConfiguraÃ§Ãµes de desenvolvimento local
.env.staging- ConfiguraÃ§Ãµes do ambiente de teste
.env.production- ConfiguraÃ§Ãµes do ambiente de produÃ§Ã£o
VariÃ¡veis â€‹â€‹de ambiente
As principais variÃ¡veis â€‹â€‹de configuraÃ§Ã£o incluem:

# Application
APP_ENV=development
PROJECT_NAME="FastAPI LangGraph Agent"
DEBUG=true

# Database
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=mydb
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

# LLM Configuration
OPENAI_API_KEY=your_openai_api_key
DEFAULT_LLM_MODEL=gpt-4o
DEFAULT_LLM_TEMPERATURE=0.7
MAX_TOKENS=4096

# Long-Term Memory
LONG_TERM_MEMORY_COLLECTION_NAME=agent_memories
LONG_TERM_MEMORY_MODEL=gpt-4o-mini
LONG_TERM_MEMORY_EMBEDDER_MODEL=text-embedding-3-small

# Observability
LANGFUSE_PUBLIC_KEY=your_public_key
LANGFUSE_SECRET_KEY=your_secret_key
LANGFUSE_HOST=https://cloud.langfuse.com

# Security
SECRET_KEY=your_secret_key_here
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Rate Limiting
RATE_LIMIT_ENABLED=true
ğŸ§  MemÃ³ria de longo prazo
O aplicativo inclui um sofisticado sistema de memÃ³ria de longo prazo baseado em mem0ai e pgvector:

CaracterÃ­sticas
Armazenamento de memÃ³ria semÃ¢ntica : Armazena e recupera memÃ³rias com base na similaridade semÃ¢ntica.
MemÃ³rias especÃ­ficas do usuÃ¡rio : Cada usuÃ¡rio possui seu prÃ³prio espaÃ§o de memÃ³ria isolado.
Gerenciamento automÃ¡tico de memÃ³ria : as memÃ³rias sÃ£o extraÃ­das, armazenadas e recuperadas automaticamente.
Busca vetorial : Utiliza pgvector para busca eficiente de similaridade.
Modelos ConfigurÃ¡veis : Modelos separados para processamento de memÃ³ria e incorporaÃ§Ãµes.
Como funciona
AdiÃ§Ã£o de memÃ³ria : Durante as conversas, informaÃ§Ãµes importantes sÃ£o extraÃ­das e armazenadas automaticamente.
RecuperaÃ§Ã£o de memÃ³ria : memÃ³rias relevantes sÃ£o recuperadas com base no contexto da conversa.
Busca na memÃ³ria : A busca semÃ¢ntica encontra memÃ³rias relacionadas em conversas.
AtualizaÃ§Ãµes de memÃ³ria : As memÃ³rias existentes podem ser atualizadas Ã  medida que novas informaÃ§Ãµes se tornam disponÃ­veis.
ğŸ¤– ServiÃ§o LLM
O serviÃ§o LLM oferece interaÃ§Ãµes robustas com modelos de linguagem, prontas para produÃ§Ã£o, com lÃ³gica de repetiÃ§Ã£o automÃ¡tica e suporte a mÃºltiplos modelos.

CaracterÃ­sticas
Suporte a mÃºltiplos modelos : Suporte prÃ©-configurado para GPT-4o, GPT-4o-mini, GPT-5 e variantes do GPT-5.
Tentativas automÃ¡ticas : Utiliza tenacidade para lÃ³gica de repetiÃ§Ã£o com recuo exponencial.
ConfiguraÃ§Ã£o de raciocÃ­nio : os modelos GPT-5 suportam nÃ­veis de esforÃ§o de raciocÃ­nio configurÃ¡veis.
Ajustes especÃ­ficos para cada ambiente : parÃ¢metros diferentes para desenvolvimento e produÃ§Ã£o.
Mecanismos de contingÃªncia : DegradaÃ§Ã£o controlada quando os modelos primÃ¡rios falham.
Modelos suportados
Modelo	Caso de uso	EsforÃ§o de raciocÃ­nio
gpt-5	Tarefas de raciocÃ­nio complexo	MÃ©dio
gpt-5-mini	Desempenho equilibrado	Baixo
gpt-5-nano	Respostas rÃ¡pidas	MÃ­nimo
gpt-4o	cargas de trabalho de produÃ§Ã£o	N / D
gpt-4o-mini	tarefas com boa relaÃ§Ã£o custo-benefÃ­cio	N / D
ConfiguraÃ§Ã£o de repetiÃ§Ã£o
Tentativas automÃ¡ticas em caso de timeouts da API, limites de taxa e erros temporÃ¡rios.
NÃºmero mÃ¡ximo de tentativas : 3
EstratÃ©gia de espera : Recuo exponencial (1s, 2s, 4s)
Registro de logs : Todas as tentativas de repetiÃ§Ã£o sÃ£o registradas com contexto.
ğŸ“ Registro AvanÃ§ado
O aplicativo usa structlog para registro estruturado e contextual com rastreamento automÃ¡tico de solicitaÃ§Ãµes.

CaracterÃ­sticas
Registro estruturado : Todos os registros sÃ£o estruturados com campos consistentes.
Contexto da solicitaÃ§Ã£o : VinculaÃ§Ã£o automÃ¡tica de request_id, session_id e user_id.
FormataÃ§Ã£o especÃ­fica do ambiente : JSON em produÃ§Ã£o, console colorido em desenvolvimento.
Rastreamento de desempenho : registro automÃ¡tico da duraÃ§Ã£o e do status das solicitaÃ§Ãµes.
Rastreamento de exceÃ§Ãµes : rastreamento completo da pilha de chamadas com preservaÃ§Ã£o do contexto.
Middleware de contexto de registro
Cada solicitaÃ§Ã£o recebe automaticamente:

ID de solicitaÃ§Ã£o exclusivo
ID da sessÃ£o (se autenticado)
ID do usuÃ¡rio (se autenticado)
Caminho e mÃ©todo da solicitaÃ§Ã£o
Estado e duraÃ§Ã£o da resposta
PadrÃµes de formato de log
Nomes de eventos : minÃºsculas_com_sublinhados
Sem strings F : passe variÃ¡veis â€‹â€‹como argumentos nomeados para filtragem adequada.
VinculaÃ§Ã£o de contexto : sempre inclua IDs e contexto relevantes.
NÃ­veis apropriados : depuraÃ§Ã£o, informaÃ§Ã£o, aviso, erro, exceÃ§Ã£o
âš¡ OtimizaÃ§Ãµes de desempenho
IntegraÃ§Ã£o uvloop
O aplicativo utiliza uvloop para melhor desempenho assÃ­ncrono (habilitado automaticamente via Makefile):

Melhorias de desempenho :

OperaÃ§Ãµes asyncio 2 a 4 vezes mais rÃ¡pidas
Menor latÃªncia para tarefas com uso intensivo de E/S
Melhor gerenciamento do pool de conexÃµes
Uso reduzido da CPU para solicitaÃ§Ãµes simultÃ¢neas
Agrupamento de conexÃµes
Banco de dados : Agrupamento de conexÃµes assÃ­ncronas com tamanho de pool configurÃ¡vel.
LangGraph Checkpointing : Pool de conexÃµes compartilhadas para persistÃªncia de estado
Redis (opcional): Pool de conexÃµes para cache
EstratÃ©gia de cache
Somente as respostas bem-sucedidas sÃ£o armazenadas em cache.
TTL configurÃ¡vel com base na volatilidade dos dados.
InvalidaÃ§Ã£o de cache em atualizaÃ§Ãµes
Suporta cache Redis ou em memÃ³ria.
ğŸ”Œ ReferÃªncia da API
Pontos de extremidade de autenticaÃ§Ã£o
POST /api/v1/auth/register- Registrar um novo usuÃ¡rio
POST /api/v1/auth/login- Autenticar e receber token JWT
POST /api/v1/auth/logout- Sair e invalidar a sessÃ£o
Pontos de extremidade de bate-papo
POST /api/v1/chatbot/chat- Enviar mensagem e receber resposta
POST /api/v1/chatbot/chat/stream- Enviar mensagem com resposta em fluxo contÃ­nuo
GET /api/v1/chatbot/history- Obter histÃ³rico de conversas
DELETE /api/v1/chatbot/history- Limpar histÃ³rico de bate-papo
SaÃºde e monitoramento
GET /health- VerificaÃ§Ã£o de integridade com status do banco de dados
GET /metrics- Ponto de extremidade de mÃ©tricas do Prometheus
Para obter documentaÃ§Ã£o detalhada da API, visite /docs(Swagger UI) ou /redoc(ReDoc) ao executar o aplicativo.

ğŸ“š Estrutura do Projeto
whatsapp-food-order/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ auth.py              # Authentication endpoints
â”‚   â”‚       â”œâ”€â”€ chatbot.py           # Chat endpoints
â”‚   â”‚       â””â”€â”€ api.py               # API router aggregation
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py                # Configuration management
â”‚   â”‚   â”œâ”€â”€ logging.py               # Logging setup
â”‚   â”‚   â”œâ”€â”€ metrics.py               # Prometheus metrics
â”‚   â”‚   â”œâ”€â”€ middleware.py            # Custom middleware
â”‚   â”‚   â”œâ”€â”€ limiter.py               # Rate limiting
â”‚   â”‚   â”œâ”€â”€ langgraph/
â”‚   â”‚   â”‚   â”œâ”€â”€ graph.py             # LangGraph agent
â”‚   â”‚   â”‚   â””â”€â”€ tools.py             # Agent tools
â”‚   â”‚   â””â”€â”€ prompts/
â”‚   â”‚       â”œâ”€â”€ __init__.py          # Prompt loader
â”‚   â”‚       â””â”€â”€ system.md            # System prompts
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ user.py                  # User model
â”‚   â”‚   â””â”€â”€ session.py               # Session model
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ auth.py                  # Auth schemas
â”‚   â”‚   â”œâ”€â”€ chat.py                  # Chat schemas
â”‚   â”‚   â””â”€â”€ graph.py                 # Graph state schemas
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ database.py              # Database service
â”‚   â”‚   â””â”€â”€ llm.py                   # LLM service with retries
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ graph.py                 # Graph utility functions
â”‚   â””â”€â”€ main.py                      # Application entry point
â”œâ”€â”€ evals/
â”‚   â”œâ”€â”€ evaluator.py                 # Evaluation logic
â”‚   â”œâ”€â”€ main.py                      # Evaluation CLI
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â””â”€â”€ prompts/                 # Evaluation metric definitions
â”‚   â””â”€â”€ reports/                     # Generated evaluation reports
â”œâ”€â”€ grafana/                         # Grafana dashboards
â”œâ”€â”€ prometheus/                      # Prometheus configuration
â”œâ”€â”€ scripts/                         # Utility scripts
â”œâ”€â”€ docker-compose.yml               # Docker Compose configuration
â”œâ”€â”€ Dockerfile                       # Application Docker image
â”œâ”€â”€ Makefile                         # Development commands
â”œâ”€â”€ pyproject.toml                   # Python dependencies
â”œâ”€â”€ schema.sql                       # Database schema
â”œâ”€â”€ SECURITY.md                      # Security policy
â””â”€â”€ README.md                        # This file
